{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../../logo.png\" alt=\"Header\" style=\"width: 800px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "@Copyright (C): 2010-2020, Shenzhen Yahboom Tech  \n",
    "@Author: Liusen  \n",
    "@Date: 2020-02-05 17:20:02  \n",
    "@LastEditors: Liusen  \n",
    "@LastEditTime: 2020-02-05 18:50:02   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os,time\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_utils\n",
    "import ipywidgets.widgets as widgets\n",
    "from image_fun import bgr8_to_jpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init camera \n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 320) # set Width\n",
    "cap.set(4, 240) # set Height\n",
    "cap.set(5, 30)  # set frame\n",
    "cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter.fourcc('M', 'J', 'P', 'G'))\n",
    "cap.set(cv2.CAP_PROP_BRIGHTNESS, 60)\n",
    "cap.set(cv2.CAP_PROP_CONTRAST, 50) \n",
    "cap.set(cv2.CAP_PROP_EXPOSURE, 156)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_widget = widgets.Image(format='jpg', width=320, height=240)\n",
    "display(image_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init tf model\n",
    "\n",
    "MODEL_NAME = 'ssdlite_mobilenet_v2_coco_2018_05_09' #fast\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb' \n",
    "PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt') \n",
    "NUM_CLASSES = 90 \n",
    "IMAGE_SIZE = (12, 8) \n",
    "fileAlreadyExists = os.path.isfile(PATH_TO_CKPT) \n",
    "\n",
    "if not fileAlreadyExists:\n",
    "    print('Model does not exsist !')\n",
    "    exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD GRAPH\n",
    "print('Loading...')\n",
    "detection_graph = tf.Graph() \n",
    "with detection_graph.as_default(): \n",
    "    od_graph_def = tf.compat.v1.GraphDef()\n",
    "    with tf.io.gfile.GFile(PATH_TO_CKPT, 'rb') as fid: \n",
    "        serialized_graph = fid.read() \n",
    "        od_graph_def.ParseFromString(serialized_graph) \n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True) \n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "print('Finish Load Graph..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(category_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dict['Name']: \", category_index[1]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    # Main\n",
    "    t_start = time.time()\n",
    "    fps = 0\n",
    "\n",
    "    with detection_graph.as_default():\n",
    "        with tf.compat.v1.Session(graph=detection_graph) as sess:\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "    #            frame = cv2.flip(frame, -1) # Flip camera vertically\n",
    "    #             frame = cv2.resize(frame,(320,240))\n",
    "                ##############\n",
    "                image_np_expanded = np.expand_dims(frame, axis=0) \n",
    "                image_tensor = detection_graph.get_tensor_by_name('image_tensor:0') \n",
    "                detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0') \n",
    "                detection_scores = detection_graph.get_tensor_by_name('detection_scores:0') \n",
    "                detection_classes = detection_graph.get_tensor_by_name('detection_classes:0') \n",
    "                num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "    #             print('Running detection..') \n",
    "                (boxes, scores, classes, num) = sess.run( \n",
    "                    [detection_boxes, detection_scores, detection_classes, num_detections], \n",
    "                    feed_dict={image_tensor: image_np_expanded}) \n",
    "\n",
    "    #             print('Done.  Visualizing..')\n",
    "                vis_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                        frame,\n",
    "                        np.squeeze(boxes),\n",
    "                        np.squeeze(classes).astype(np.int32),\n",
    "                        np.squeeze(scores),\n",
    "                        category_index,\n",
    "                        use_normalized_coordinates=True,\n",
    "                        line_thickness=8)\n",
    "\n",
    "                for i in range(0, 10):\n",
    "                    if scores[0][i] >= 0.5:\n",
    "                        print(category_index[int(classes[0][i])]['name'])\n",
    "                ##############\n",
    "                fps = fps + 1\n",
    "                mfps = fps / (time.time() - t_start)\n",
    "                cv2.putText(frame, \"FPS \" + str(int(mfps)), (10,10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 2)\n",
    "                image_widget.value = bgr8_to_jpeg(frame)\n",
    "\n",
    "                k = cv2.waitKey(1) & 0xff\n",
    "                if k == 27: # press 'ESC' to quit\n",
    "                    break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release() #After using, we need to release the object, otherwise it will be occupied and cannot be used in the next program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
